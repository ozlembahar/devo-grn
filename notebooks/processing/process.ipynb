{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pySCENIC workflow - results\n",
    "4.10.23, 50 runs\n",
    "\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os.path import basename, normpath\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir_glob = \"/Users/danabarilan/Documents/forMasters/Intenship/code/devo-grn/results/results_041023/run_*/\"\n",
    "results_dir = \"/Users/danabarilan/Documents/forMasters/Intenship/code/devo-grn/results/results_041023/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./figures/\"):\n",
    "    os.mkdir(\"./figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each run:\n",
    "* convert regulons.pkl to csv\n",
    "* add size column for each regulon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in glob(results_dir_glob):  # get a list of all sub directories\n",
    "    with open(folder+'regulons.pkl', 'rb') as f: \n",
    "        regulon = pickle.load(f)\n",
    "    # run = basename(normpath(folder))\n",
    "    # print(run)\n",
    "        # get regulon results from pkl file to df and save as csv - for readability\n",
    "        reg_df = pd.DataFrame({\n",
    "            'TF': [reg.transcription_factor for reg in regulon],\n",
    "            'genes': [list(reg.genes) for reg in regulon],\n",
    "            'score': [reg.score for reg in regulon]\n",
    "        })\n",
    "        reg_df['size'] = reg_df['genes'].apply(lambda x: len(x))\n",
    "        reg_df = reg_df.set_index('TF')\n",
    "        reg_df.to_csv(folder + 'regulons.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect consistent results\n",
    "TFs and genes that appear in >80% of the runs (40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs_counter = Counter()\n",
    "for folder in glob(results_dir_glob):\n",
    "    regulons_df = pd.read_csv(folder+'regulons.csv', index_col=0)\n",
    "    tfs_counter.update(regulons_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot TFs count distrubution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs_counts_series = pd.Series(tfs_counter).sort_values(ascending=False)  # sorted Series of TFs counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, \n",
    "                                    gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "sns.boxenplot(tfs_counts_series, ax=ax_box)\n",
    "sns.histplot(tfs_counts_series, ax=ax_hist, bins=n_runs)\n",
    "sns.despine(ax=ax_box, left=True)\n",
    "plt.axvline(int(n_runs*0.8), color='red')\n",
    "plt.savefig(\"./figures/tfs_counts.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs_80 = tfs_counts_series[tfs_counts_series > n_runs*0.8]\n",
    "len(tfs_80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save for each run the consistent regulons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in glob(results_dir_glob):\n",
    "    regulons_df = pd.read_csv(folder+'regulons.csv', index_col=0)\n",
    "    regulons_top_freq = regulons_df.loc[[tf for tf in regulons_df.index if tf in tfs_80.index]]\n",
    "    regulons_top_freq.to_csv(folder + 'regulons_top80.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate gene counts for the same TF (among top 80% TFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = pd.concat([pd.read_csv(folder + 'regulons_top80.csv', index_col=0) for folder in glob(results_dir_glob)])\n",
    "all_dfs_genes = all_dfs['genes']  # keep only genes column, discard size of regulon and score\n",
    "all_dfs_genes = all_dfs_genes.apply(literal_eval) # convert string to list of genes\n",
    "all_dfs_genes = all_dfs_genes.explode()  # convert to couples of TF-gene\n",
    "all_dfs_genes = pd.DataFrame(all_dfs_genes).rename({'genes': 'gene'}, axis='columns') # to dataframe\n",
    "gene_counts = all_dfs_genes.groupby(['TF', 'gene']).size().to_frame('count') # count couples fo TF - gene\n",
    "gene_counts.to_csv(results_dir+\"gene_counts.csv\") # save to csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_counts = gene_counts.reset_index()\n",
    "len(gene_counts.gene.unique())  # number of unique genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot genes counts (from TF-gene couples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, \n",
    "                                    gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "sns.boxenplot(gene_counts['count'], ax=ax_box)\n",
    "sns.histplot(gene_counts['count'], ax=ax_hist, bins=n_runs)\n",
    "sns.despine(ax=ax_box, left=True)\n",
    "plt.axvline(int(n_runs*0.8), color='red')\n",
    "plt.savefig(\"./figures/genes_counts.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save AUCell score matrix of only top 80% for each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in glob(results_dir_glob):\n",
    "    auc_mtx = pd.read_csv(folder + \"AUCell_mat.csv\", index_col=0)\n",
    "    reg_top80 = pd.read_csv(folder + \"regulons_top80.csv\", index_col=0)\n",
    "    # keep AUC_mtx TFs that are in reg_top80:\n",
    "    auc_mtx_top80 = auc_mtx.loc[:, [col for col in auc_mtx if col.strip(\"(+)\") in reg_top80.index.values.tolist()]]\n",
    "    auc_mtx_top80.to_csv(folder + 'AUCell_mat_top80.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmaps for top TFs for each run (AUCell score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_df = pd.read_csv(\"/home/dbarila/devo-grn/data/cell_type.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create and save heatmaps as png for each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut = dict(zip(types_df.type.unique(), sns.color_palette(\"tab20\", len(types_df.type.unique()))))\n",
    "cell_colors = types_df.type.map(lut)\n",
    "\n",
    "for folder in glob(results_dir_glob):\n",
    "    auc_mtx_top80 = pd.read_csv(folder + \"AUCell_mat_top80.csv\", index_col=0)\n",
    "    # fix colors:\n",
    "    row_colors = auc_mtx_top80.merge(cell_colors, how='left', left_index=True, right_index=True).type\n",
    "    # create heatmap abd save to results\n",
    "    ax= sns.clustermap(auc_mtx_top80, figsize=(12,12),yticklabels=True, xticklabels=True, row_colors=row_colors)\n",
    "    ax.savefig(folder + \"top80_heatmap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handels = [Patch(facecolor=lut[name]) for name in lut]\n",
    "plt.legend(handels, lut, title='cell type', framealpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUCell mean score per cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut = dict(zip(types_df.type.unique(), sns.color_palette(\"tab20\", len(types_df.type.unique()))))\n",
    "cell_colors = types_df.type.map(lut)\n",
    "\n",
    "# auc_mtx = pd.read_csv(\"../results/run_01/top80_heatmap.png\", index_col=0)\n",
    "# types df : cell (index) | type\n",
    "for folder in glob(results_dir_glob):\n",
    "    auc_mtx_top80 = pd.read_csv(folder + \"AUCell_mat_top80.csv\", index_col=0)\n",
    "    auc_type = auc_mtx_top80.merge(types_df, how='left', left_index=True, right_index=True)\n",
    "    auc_type = auc_type.groupby(\"type\").mean()\n",
    "    # visuzlize \n",
    "    ax = sns.clustermap(auc_type, figsize=(12,12),yticklabels=True, xticklabels=True)\n",
    "    ax.savefig(folder + \"top80_heatmap_type.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary representation (only tio 80%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyscenic tutorial https://pyscenic.readthedocs.io/en/latest/faq.html \n",
    "def plot_binarization(auc_mtx: pd.DataFrame, regulon_name: str, threshold: float, ax=None) -> None:\n",
    "    \"\"\"\n",
    "    Plot the \"binarization\" process for the given regulon.\n",
    "\n",
    "    :param auc_mtx: The dataframe with the AUC values for all cells and regulons (n_cells x n_regulons).\n",
    "    :param regulon_name: The name of the regulon.\n",
    "    :param bins: The number of bins to use in the AUC histogram.\n",
    "    :param threshold: The threshold to use for binarization.\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        ax=plt.gca()\n",
    "   \n",
    "    auc_mtx[regulon_name].hist(ax=ax, bins='auto')  # originally bins are chosen to be 200\n",
    "\n",
    "    ylim = ax.get_ylim()\n",
    "    ax.plot([threshold]*2, ylim, 'r:')\n",
    "    ax.set_ylim(ylim)\n",
    "    # ax.set_xlim(0.12,0.35)\n",
    "    ax.set_xlabel('AUC')\n",
    "    ax.set_ylabel('# cells')\n",
    "    ax.set_title(regulon_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyscenic.binarization import binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut = dict(zip(types_df.type.unique(), sns.color_palette(\"tab20\", len(types_df.type.unique()))))\n",
    "cell_colors = types_df.type.map(lut)\n",
    "\n",
    "for folder in glob(results_dir_glob):\n",
    "    auc_mtx_top80 = pd.read_csv(folder + \"AUCell_mat_top80.csv\", index_col=0)\n",
    "    binary = binarize(auc_mtx_top80)\n",
    "    binary_aucell = binary[0]  # because binarize returns a touple of (df, Series of thresholds)\n",
    "    row_colors = binary_aucell.merge(cell_colors, how='left', left_index=True, right_index=True).type\n",
    "    ax = sns.clustermap(binary_aucell, figsize=(12,12),yticklabels=True, xticklabels=True, row_colors=row_colors)\n",
    "    ax.savefig(folder + \"top80_binary_heatmap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No MG cells analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the SC data from MG cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devo-grn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
